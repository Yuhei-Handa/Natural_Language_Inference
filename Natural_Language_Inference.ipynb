{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ準備\n",
    "\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"shunk031/JGLUE\",\n",
    "    name=\"JNLI\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "valid_dataset = load_dataset(\n",
    "    \"shunk031/JGLUE\",\n",
    "    name=\"JNLI\",\n",
    "    split=\"validation\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence_pair_id', 'yjcaptions_id', 'sentence1', 'sentence2', 'label']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前提文と仮説文を結合、ラベルを加え出力\n",
    "\n",
    "from transformers import BatchEncoding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def preprocess_text_pair_classfication(example):\n",
    "    encoded_example = tokenizer(example[\"sentence1\"], example[\"sentence2\"], max_length=128)\n",
    "    encoded_example[\"labels\"] = example[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "    return encoded_example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = train_dataset.features[\"label\"]\n",
    "\n",
    "label2id = {label:id for id, label in enumerate(class_label.names)}\n",
    "id2label = {id:label for id, label in enumerate(class_label.names)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, BatchEncoding, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_arg = TrainingArguments(\n",
    "    output_dir=\"./output/\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "def calc_accuracy(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\":(predictions == labels).mean()}\n",
    "\n",
    "class_label = train_dataset.features[\"label\"]\n",
    "\n",
    "label2id = {label:id for id, label in enumerate(class_label.names)}\n",
    "id2label = {id:label for id, label in enumerate(class_label.names)}\n",
    "\n",
    "\n",
    "model_name = \"Mizuiro-sakura/luke-japanese-base-finetuned-jnli\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encoded_train_dataset = train_dataset.map(\n",
    "    preprocess_text_pair_classfication\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "encoded_valid_dataset = train_dataset.map(\n",
    "    preprocess_text_pair_classfication\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=class_label.num_classes,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    args=train_arg,\n",
    "    compute_metrics=calc_accuracy\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bd7ba668a94f37951b49bbe4a5c213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3768, 'learning_rate': 1.605095541401274e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad525e77c7f460890a13086b061bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08473782241344452, 'eval_accuracy': 0.9695611019777811, 'eval_runtime': 11.3438, 'eval_samples_per_second': 1769.508, 'eval_steps_per_second': 27.68, 'epoch': 1.0}\n",
      "{'loss': 0.1043, 'learning_rate': 1.2050955414012739e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc33fce3b59240669f3670fc12961ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.046230170875787735, 'eval_accuracy': 0.9863498231455189, 'eval_runtime': 11.2132, 'eval_samples_per_second': 1790.125, 'eval_steps_per_second': 28.003, 'epoch': 2.0}\n",
      "{'loss': 0.0766, 'learning_rate': 8.05095541401274e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b69c1f15094e4186ec5e70180a4cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.027775323018431664, 'eval_accuracy': 0.9931749115727594, 'eval_runtime': 11.2561, 'eval_samples_per_second': 1783.306, 'eval_steps_per_second': 27.896, 'epoch': 3.0}\n",
      "{'loss': 0.0526, 'learning_rate': 4.0509554140127395e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70681df6248445348de20769e810d38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021645167842507362, 'eval_accuracy': 0.9943705475016191, 'eval_runtime': 11.2695, 'eval_samples_per_second': 1781.176, 'eval_steps_per_second': 27.863, 'epoch': 4.0}\n",
      "{'loss': 0.0396, 'learning_rate': 5.0955414012738854e-08, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c048b6c1d14ec7a5066e14e2d13800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017589282244443893, 'eval_accuracy': 0.9958650924126937, 'eval_runtime': 11.1759, 'eval_samples_per_second': 1796.1, 'eval_steps_per_second': 28.096, 'epoch': 5.0}\n",
      "{'train_runtime': 770.5323, 'train_samples_per_second': 130.254, 'train_steps_per_second': 1.019, 'train_loss': 0.12996883999769854, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=785, training_loss=0.12996883999769854, metrics={'train_runtime': 770.5323, 'train_samples_per_second': 130.254, 'train_steps_per_second': 1.019, 'train_loss': 0.12996883999769854, 'epoch': 5.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
